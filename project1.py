# -*- coding: utf-8 -*-
"""project1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PxAJajlpJzsBtRqI3YgDjRGHlpqINM83
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_boston
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error

boston=load_boston()

boston.keys()

boston.DESCR

boston.feature_names

boston.target

data=boston.data
data.shape

data=pd.DataFrame(data=data,columns=boston.feature_names)
data.head()

data['price']=boston.target
data.head()

data.describe()

data.info()

sns.pairplot(data)

data.hist(figsize=(12,12))

corrmat=data.corr()
corrmat

corrmat.index.values

def getCorrelationFeature(corrdata,threshold):
    feature=[]
    value=[]
    for i,index in enumerate(corrdata.index):
        if abs(corrdata[index])>threshold:
            feature.append(index)
            value.append(corrdata[index])
    df=pd.DataFrame(data=value,index=feature,columns=['corr values'])
    return df

threshold=0.50
corr_value=getCorrelationFeature(corrmat['price'],threshold)
corr_value

corr_value.index.values

correlated_data=data[corr_value.index]
correlated_data.head()

sns.pairplot(correlated_data)
plt.tight_layout()

x=correlated_data.drop(labels=['price'],axis=1)
y=correlated_data['price']
x.head()

x = data.iloc[:, :-1].values
y = data.iloc[:, 13].values

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=30)

x_train.shape,x_test.shape

model=LinearRegression()
model.fit(x_train,y_train)

y_predict=model.predict(x_test)
y_predict

df=pd.DataFrame(data=[y_predict,y_test])
df.T

from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error
mse = mean_squared_error(y_test, y_predict)
mae=mean_absolute_error(y_test,y_predict)
score=r2_score(y_test,y_predict)
print('mse=', mse)
print('mae=',mae)
print('r2_score=',score)

import statsmodels.api as sm
x = np.append(arr = np.ones((506, 1)).astype(int), values = x, axis = 1)
x_opt = x[:, [0,1,2,3,4,5,6,7,8,9,10,11,12]]
regressor_OLS = sm.OLS(endog = y, exog = x_opt).fit()
regressor_OLS.summary()

model.coef_

model.intercept_

import xgboost as xgb

xg_reg = xgb.XGBRegressor(objective='reg:squarederror', gamma=0.2, max_depth=6)
xg_reg.fit(x_train, y_train)

pred = xg_reg.predict(x_test)

mse = mean_squared_error(y_test, pred)
mae=mean_absolute_error(y_test, pred)
score=r2_score(y_test, pred)
print('mse=', mse)
print('mae=',mae)
print('r2_score=',score)

from sklearn.model_selection import GridSearchCV

parameters = [{'learning_rate':[0.1, 0.2, 0.01], 'gamma':[i/10.0 for i in range(0,5)], 'max_depth':[1,2,3,4,5,6], 'max_depth':[1,2,3,4,5,6]}]

grid_search = GridSearchCV(estimator = xg_reg,
                           param_grid = parameters, 
                           scoring = 'r2',
                           cv = 10,
                           n_jobs=-1)
grid_search = grid_search.fit(x_train, y_train)
best_score = grid_search.best_score_
best_parameters = grid_search.best_params_
print(best_score)
print(best_parameters)

